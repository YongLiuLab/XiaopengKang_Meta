{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import meta_roi\n",
    "from mask import NiiMask\n",
    "from scipy.special import softmax\n",
    "from draw_results import plot_correlation_joint\n",
    "\n",
    "def get_weights(mask, csv_prefix, gmv=True):\n",
    "    if gmv:\n",
    "        roi_models = meta_roi.meta_gmv(2, 0, mask, csv_prefix=csv_prefix, save_nii=False)\n",
    "    else:\n",
    "        roi_models = meta_roi.meta_ct(2, 0, mask, csv_prefix=csv_prefix, save_nii=False, save_gii=False)\n",
    "\n",
    "    rois = []\n",
    "    ess = []\n",
    "    for k, model in roi_models.items():\n",
    "        rois.append(k)\n",
    "        ess.append(model.total_effect_size)\n",
    "\n",
    "    data = {'roi': rois,\n",
    "            'es': ess}\n",
    "\n",
    "    # Convert the dictionary into DataFrame\n",
    "    es_df = pd.DataFrame(data)\n",
    "    es_df = es_df.sort_values(by=['roi'])\n",
    "\n",
    "    ess = es_df['es'].values\n",
    "    ess = np.abs(ess)\n",
    "    softmax_ess = softmax(ess)\n",
    "    return softmax_ess, es_df\n",
    "\n",
    "def append_infos(center, target_label, center_names,\n",
    "                person_names, MMSEs, ages, tivs,\n",
    "                genders, origin_label):\n",
    "    persons = center.get_by_label(target_label)\n",
    "    if persons:\n",
    "        center_names += [center.name for person in persons]\n",
    "        person_names += [person.filename for person in persons]\n",
    "        MMSEs += center.get_MMSEs(target_label)[0].tolist()\n",
    "        ages += center.get_ages(target_label)[0].tolist()\n",
    "        tivs += center.get_tivs(target_label)[0].tolist()\n",
    "        genders += center.get_males(target_label)[0].tolist()\n",
    "        origin_label += [target_label for person in persons]\n",
    "\n",
    "    return center_names, person_names, MMSEs, ages, tivs, genders, origin_label\n",
    "\n",
    "def get_features(all_features, prefix, center, target_label, pss=[], get_total=True, weights=None, avg='mean'):\n",
    "    persons = center.get_by_label(target_label)\n",
    "    if persons:\n",
    "        features, *_ = center.get_csv_values(persons=persons, prefix=prefix, flatten=True)\n",
    "        if get_total:\n",
    "            if avg == 'mean':\n",
    "                pss += np.mean(features, axis=1).tolist()\n",
    "            elif avg == 'weighted' and weights is not None:\n",
    "                for feature in features:\n",
    "                    pss.append(np.dot(feature, weights))\n",
    "\n",
    "        if all_features is None:\n",
    "            all_features = features\n",
    "        else:\n",
    "            all_features = np.vstack((all_features, features))\n",
    "    if get_total:\n",
    "        return all_features, pss\n",
    "    else:\n",
    "        return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = datasets.load_centers_all()\n",
    "\n",
    "gmv = True\n",
    "if gmv:\n",
    "    origin_feature_prefix = 'neurocombat_gmv2/{}.csv'\n",
    "    ps_prefix = 'ps_g_agt/{}.csv'\n",
    "    meta_csv_prefix='roi_gmv_removed'\n",
    "else:\n",
    "    origin_feature_prefix = 'neurocombat_ct2/{}.csv'\n",
    "    ps_prefix = 'ps_c_ag/{}.csv'\n",
    "    meta_csv_prefix='roi_ct_removed'\n",
    "\n",
    "\n",
    "center_names = []\n",
    "person_names = []\n",
    "MMSEs = []\n",
    "ages = []\n",
    "tivs = []\n",
    "genders = []\n",
    "origin_label = []\n",
    "\n",
    "mask = NiiMask('./data/mask/rBN_Atlas_246_1mm.nii')\n",
    "weights, es_df = get_weights(mask, meta_csv_prefix, gmv=gmv)\n",
    "\n",
    "all_ps = None\n",
    "pss = []\n",
    "\n",
    "all_gmvs = None\n",
    "gmv_ps = []\n",
    "\n",
    "target_labels = [0, 1, 2]\n",
    "for center in centers:\n",
    "    for target_label in target_labels:\n",
    "        center_names, person_names, MMSEs, ages, tivs, genders, origin_label = append_infos(center, target_label, center_names,\n",
    "                                                                                        person_names, MMSEs, ages, tivs,\n",
    "                                                                                        genders, origin_label)\n",
    "        all_ps, pss = get_features(all_ps, ps_prefix, center, target_label, pss, get_total=True, weights=weights, avg='weighted')\n",
    "        all_gmvs, gmv_ps = get_features(all_gmvs, origin_feature_prefix, center, target_label, gmv_ps, get_total=True, weights=weights, avg='weighted')\n",
    "\n",
    "data = {'Center_name': center_names,\n",
    "        'Person_name': person_names,\n",
    "        'MMSE': MMSEs,\n",
    "        'Age':ages,\n",
    "        'TIV':tivs,\n",
    "        'gender':genders,\n",
    "        'origin_label':origin_label,\n",
    "        'Mean_PS': pss,\n",
    "        'Mean_GMV': gmv_ps,}\n",
    "\n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "\n",
    "a = es_df['es'].values.tolist()\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "hue = []\n",
    "\n",
    "for i in range(3):\n",
    "    mean_nc_ps = np.mean(all_ps[df['origin_label']==i], axis=0)\n",
    "    print(pearsonr(mean_nc_ps,a))\n",
    "\n",
    "    x += mean_nc_ps.tolist()\n",
    "    y += a\n",
    "    hue += [i for _ in mean_nc_ps]\n",
    "    \n",
    "data = {'x':x,\n",
    "    \"y\":y,\n",
    "    'hue':hue}\n",
    "data_df = pd.DataFrame(data)\n",
    "\n",
    "g = sns.lmplot(\n",
    "    data=data_df,\n",
    "    x='x', y='y', hue='hue',\n",
    "    height=5, scatter_kws={'alpha':0.4},\n",
    "    palette='Set2'\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"white\")\n",
    "sns.displot(df, height=5, aspect=2, x='Mean_PS', hue='origin_label', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NC')\n",
    "print(np.mean(df['Mean_PS'][df['origin_label'].isin([0])]))\n",
    "print(np.std(df['Mean_PS'][df['origin_label'].isin([0])]))\n",
    "print('MCI')\n",
    "print(np.mean(df['Mean_PS'][df['origin_label'].isin([1])]))\n",
    "print(np.std(df['Mean_PS'][df['origin_label'].isin([1])]))\n",
    "print('AD')\n",
    "print(np.mean(df['Mean_PS'][df['origin_label'].isin([2])]))\n",
    "print(np.std(df['Mean_PS'][df['origin_label'].isin([2])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nc_ps = np.mean(all_ps[df['origin_label']==2], axis=0)\n",
    "print(np.argmin(mean_nc_ps), mean_nc_ps[np.argmin(mean_nc_ps)])\n",
    "print(np.argmax(mean_nc_ps), mean_nc_ps[np.argmax(mean_nc_ps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nc_ps[192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_ps[:, 87]\n",
    "hue = df['origin_label']\n",
    "sns.displot(df, aspect=2, x=x, hue=hue, palette='Set2', bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = all_ps[:, 57]\n",
    "hue = df['origin_label']\n",
    "sns.displot(df,aspect=2, x=x, hue=hue, palette='Set2', bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_joint(df['Mean_PS'], df['MMSE'], x_label='Peasonal Score', y_label='MMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "for i in range(246):\n",
    "    r, p = pearsonr(all_ps[:, i], df['Age'])\n",
    "    print(i, r, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_joint(df['TIV'], df['Mean_GMV'], y_label='Weighted Sum GMV',  x_label='TIV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_joint(df['TIV'], df['Mean_PS'], y_label='Individual Score', x_label='TIV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_joint(df['Age']*100,df['Mean_PS'], y_label='Individual Score', x_label='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_joint(df['Age']*100,df['Mean_GMV'], y_label='Weighted Sum GMV', x_label='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "\n",
    "k_fold = KFold(10)\n",
    "\n",
    "X = copy.deepcopy(all_ps)\n",
    "y = df['origin_label'].values\n",
    "a = df['Center_name'].values\n",
    "b = df['Person_name'].values\n",
    "c = df['Mean_PS'].values\n",
    "\n",
    "# shuffle\n",
    "p = np.random.permutation(len(X))\n",
    "X = X[p]\n",
    "y = y[p]\n",
    "a = a[p]\n",
    "b = b[p]\n",
    "c = c[p]\n",
    "\n",
    "f1s = []\n",
    "new_center_names = []\n",
    "new_person_names = []\n",
    "new_labels = []\n",
    "new_person_scores = []\n",
    "for k, (train, test) in enumerate(k_fold.split(X, y)):\n",
    "    model = RandomForestClassifier()\n",
    "    scaler = StandardScaler()\n",
    "    x_train = X[train]\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "    model.fit(x_train, y[train])\n",
    "    x_test = scaler.transform(X[test])\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    f1 = f1_score(y[test], y_pred, average='macro')\n",
    "    cm = confusion_matrix(y[test], y_pred)\n",
    "    print(f'fold:{k}, f1:{f1}')\n",
    "    print(cm)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    new_center_names += a[test].tolist()\n",
    "    new_person_names += b[test].tolist()\n",
    "    new_labels += y_pred.tolist()\n",
    "    new_person_scores += c[test].tolist()\n",
    "\n",
    "predict_dict = {\n",
    "'Center_name':new_center_names,\n",
    "'Person_name':new_person_names,\n",
    "'Predict_label':new_labels\n",
    "}\n",
    "predict_df = pd.DataFrame(predict_dict)\n",
    "predict_df = predict_df.merge(df, on=['Center_name', 'Person_name'])\n",
    "print(np.mean(f1s), np.std(f1s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Misclassified Personal Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sub_df = predict_df.query('origin_label==1 & Predict_label==0')\n",
    "sns.displot(sub_df, x='Mean_PS', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sub_df = predict_df.query('origin_label==1 & Predict_label==2')\n",
    "sns.displot(sub_df, x='Mean_PS', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sub_df = predict_df.query('origin_label==2 & Predict_label==0')\n",
    "sns.displot(sub_df, x='Mean_PS', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxenplot(data=predict_df, y='Mean_PS', x='Predict_label', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = predict_df.query('origin_label==1')\n",
    "sns.boxenplot(data=sub_df, x='Predict_label', y='Mean_PS', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Misclassified Age, gender, tiv, MMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = predict_df.query('origin_label==1')\n",
    "sns.boxenplot(data=sub_df, x='Predict_label', y='Age', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = predict_df.query('origin_label==1')\n",
    "sns.boxenplot(data=sub_df, x='Predict_label', y='TIV', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = predict_df.query('origin_label==1')\n",
    "sns.boxenplot(data=sub_df, x='Predict_label', y='MMSE', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Misclassified ADNI clinical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "def get_clinical_value(info_df, df, clinical_name):\n",
    "    values = []\n",
    "    for label, row in df.iterrows():\n",
    "        try:\n",
    "            series = info_df.loc[row['Person_name']]\n",
    "            value = series[clinical_name]\n",
    "            if isinstance(value, str):\n",
    "                continue\n",
    "            if not np.isnan(value):\n",
    "                values.append(float(value))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return values\n",
    "\n",
    "info_df = pd.read_csv('./data/center_info/ADNI/ADNIMERGE_BL.csv', index_col=0)\n",
    "column_names = ['FAQ', 'FDG', 'ABETA', 'TAU', 'PTAU', 'ADAS11', 'ADAS13', 'ADASQ4',\n",
    "                'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'RAVLT_perc_forgetting']\n",
    "\n",
    "sub_df1 = predict_df.query('origin_label==1 & Predict_label==0')\n",
    "sub_df2 = predict_df.query('origin_label==1 & Predict_label==1')\n",
    "sub_df3 = predict_df.query('origin_label==1 & Predict_label==2')\n",
    "\n",
    "for column_name in column_names:\n",
    "    values1 = get_clinical_value(info_df, sub_df1, column_name)\n",
    "    values2 = get_clinical_value(info_df, sub_df2, column_name)\n",
    "    values3 = get_clinical_value(info_df, sub_df3, column_name)\n",
    "    values = values1 + values2 + values3\n",
    "    predict_labels = [0 for _ in values1] + [1 for _ in values2] + [2 for _ in values3]\n",
    "    ax = sns.boxenplot(y=values, x=predict_labels, palette='Set2')\n",
    "    ax.set_title(column_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = info_df.merge(predict_df, left_on='PTID', right_on='Person_name')\n",
    "ax = sns.boxenplot(data=tmp_df, y='ABETA', x='origin_label', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, kmeans_plusplus\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "tmpx = []\n",
    "tmpy1 = []\n",
    "tmpy2 = []\n",
    "tmpy3 = []\n",
    "\n",
    "input_features = all_ps[df['origin_label'].isin([1, 2])]\n",
    "input_features = minmax_scale(input_features, axis=1)\n",
    "\n",
    "for k in range(2, 10):\n",
    "    method = AgglomerativeClustering(k)\n",
    "    clustering = method.fit(input_features)\n",
    "\n",
    "    labels = method.labels_\n",
    "    sil = silhouette_score(input_features, labels)\n",
    "    cal = calinski_harabasz_score(input_features, labels)\n",
    "    dav = davies_bouldin_score(input_features, labels)\n",
    "    tmpx.append(k)\n",
    "    tmpy1.append(sil)\n",
    "    tmpy2.append(cal)\n",
    "    tmpy3.append(dav)\n",
    "plt.plot(tmpx, tmpy1, label='silhouette', linewidth=3)\n",
    "plt.show()\n",
    "plt.plot(tmpx, tmpy2, label='calinski')\n",
    "plt.show()\n",
    "plt.plot(tmpx, tmpy3, label='davies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, SpectralClustering\n",
    "import pickle\n",
    "\n",
    "cluster = 4\n",
    "\n",
    "# Features performed Clustering\n",
    "sub_df = df[df['origin_label'].isin([1,2])]\n",
    "all_features = all_ps\n",
    "all_features = all_features[df['origin_label'].isin([1,2])]\n",
    "\n",
    "method = KMeans(n_clusters=cluster)\n",
    "clustering = method.fit(all_features)\n",
    "sub_df['Subtype_label'] = clustering.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f'./results_0401/subtype/g_agt{cluster}'\n",
    "sub_df.to_csv(os.path.join(out_dir, 'subtype.csv'))\n",
    "\n",
    "with open(os.path.join(out_dir, 'clustering.pkl'), 'wb') as f:\n",
    "    pickle.dump(clustering, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from mask import NiiMask\n",
    "from gene_analysis import plsr\n",
    "import pickle\n",
    "\n",
    "mask_path = './data/mask/rBN_Atlas_246_1mm.nii'\n",
    "mask = NiiMask(mask_path)\n",
    "\n",
    "sub_df = pd.read_csv(os.path.join(out_dir, 'subtype.csv'))\n",
    "all_labels = sub_df['Subtype_label'].values\n",
    "\n",
    "# Features performed T-test using existing subtype labels\n",
    "all_features = all_ps\n",
    "all_nc_features = all_features[df['origin_label'].values==0]\n",
    "all_features = all_features[df['origin_label'].isin([1,2])]\n",
    "\n",
    "ls = np.unique(all_labels)\n",
    "for l in ls:\n",
    "    all_features_label = None\n",
    "    for feature, label in zip(all_features, all_labels):\n",
    "        if label == l:\n",
    "            if all_features_label is None:\n",
    "                all_features_label = feature\n",
    "            else:\n",
    "                all_features_label = np.vstack((all_features_label, feature))\n",
    "    ts, ps = ttest_ind(all_features_label, all_nc_features, axis=0)\n",
    "\n",
    "    all_ts = dict(zip(range(1, len(ts)+1), ts))\n",
    "    model = plsr(all_ts, n_components=5, \n",
    "                n_perm=1, n_boot=1,\n",
    "                gene_path='./data/gene/expression.csv',\n",
    "                out_path=os.path.join(out_dir,f'gene/{l}.csv'))\n",
    "    with open(os.path.join(out_dir, f'gene/model_{l}.pkl'), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    ts = [t if p<0.001/len(ts) else 0 for t, p in zip(ts, ps)]\n",
    "    ts = dict(zip(range(1, len(ts)+1), ts))\n",
    "    mask.save_values(ts, os.path.join(out_dir, f'subtype{l}.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in ls:\n",
    "    with open(os.path.join(out_dir, f'gene/model_{l}.pkl'), 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(model.varexp)\n",
    "    print(model.permres.pvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subtype plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "\n",
    "load_dir = f'./results_0401/subtype/g_agt4'\n",
    "sub_df = pd.read_csv(os.path.join(load_dir, 'subtype.csv'))\n",
    "sub_df['Age'] = sub_df['Age']*100\n",
    "with open(os.path.join(load_dir, 'clustering.pkl'), 'rb') as f:\n",
    "    method = pickle.load(f)\n",
    "\n",
    "print(sub_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ['#3caf77', '#4d5aaf', '#ffd900', '#d15d55', '#ef7b1b', \"#34a0b1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset subtype values for visual display\n",
    "sub_df.loc[sub_df.Subtype_label == 0, 'Subtype_label'] = 11\n",
    "sub_df.loc[sub_df.Subtype_label == 1, 'Subtype_label'] = 12\n",
    "sub_df.loc[sub_df.Subtype_label == 2, 'Subtype_label'] = 13\n",
    "sub_df.loc[sub_df.Subtype_label == 3, 'Subtype_label'] = 14\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 11, 'Subtype_label'] = 4\n",
    "sub_df.loc[sub_df.Subtype_label == 12, 'Subtype_label'] = 3\n",
    "sub_df.loc[sub_df.Subtype_label == 13, 'Subtype_label'] = 1\n",
    "sub_df.loc[sub_df.Subtype_label == 14, 'Subtype_label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset subtype values for visual display\n",
    "sub_df.loc[sub_df.Subtype_label == 0, 'Subtype_label'] = 11\n",
    "sub_df.loc[sub_df.Subtype_label == 1, 'Subtype_label'] = 12\n",
    "sub_df.loc[sub_df.Subtype_label == 2, 'Subtype_label'] = 13\n",
    "sub_df.loc[sub_df.Subtype_label == 3, 'Subtype_label'] = 14\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 11, 'Subtype_label'] = 4\n",
    "sub_df.loc[sub_df.Subtype_label == 12, 'Subtype_label'] = 3\n",
    "sub_df.loc[sub_df.Subtype_label == 13, 'Subtype_label'] = 1\n",
    "sub_df.loc[sub_df.Subtype_label == 14, 'Subtype_label'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset subtype values for visual display\n",
    "sub_df.loc[sub_df.Subtype_label == 0, 'Subtype_label'] = 11\n",
    "sub_df.loc[sub_df.Subtype_label == 1, 'Subtype_label'] = 12\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 11, 'Subtype_label'] = 2\n",
    "sub_df.loc[sub_df.Subtype_label == 12, 'Subtype_label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset subtype values for visual display\n",
    "sub_df.loc[sub_df.Subtype_label == 0, 'Subtype_label'] = 11\n",
    "sub_df.loc[sub_df.Subtype_label == 1, 'Subtype_label'] = 12\n",
    "sub_df.loc[sub_df.Subtype_label == 2, 'Subtype_label'] = 13\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 11, 'Subtype_label'] = 3\n",
    "sub_df.loc[sub_df.Subtype_label == 12, 'Subtype_label'] = 2\n",
    "sub_df.loc[sub_df.Subtype_label == 13, 'Subtype_label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset subtype values for visual display\n",
    "sub_df.loc[sub_df.Subtype_label == 0, 'Subtype_label'] = 11\n",
    "sub_df.loc[sub_df.Subtype_label == 1, 'Subtype_label'] = 12\n",
    "sub_df.loc[sub_df.Subtype_label == 2, 'Subtype_label'] = 13\n",
    "sub_df.loc[sub_df.Subtype_label == 3, 'Subtype_label'] = 14\n",
    "sub_df.loc[sub_df.Subtype_label == 4, 'Subtype_label'] = 15\n",
    "sub_df.loc[sub_df.Subtype_label == 5, 'Subtype_label'] = 16\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 11, 'Subtype_label'] = 4\n",
    "sub_df.loc[sub_df.Subtype_label == 12, 'Subtype_label'] = 6\n",
    "sub_df.loc[sub_df.Subtype_label == 13, 'Subtype_label'] = 5\n",
    "sub_df.loc[sub_df.Subtype_label == 14, 'Subtype_label'] = 3\n",
    "sub_df.loc[sub_df.Subtype_label == 15, 'Subtype_label'] = 2\n",
    "sub_df.loc[sub_df.Subtype_label == 16, 'Subtype_label'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS, TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "input_features = all_ps[df['origin_label'].isin([1,2])]\n",
    "input_features = np.array(input_features)\n",
    "embeded_features = tsne.fit_transform(input_features)\n",
    "x = embeded_features.T[0]\n",
    "y = embeded_features.T[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./results_0401/GMV_tsne_x.npy', x)\n",
    "np.save('./results_0401/GMV_tsne_y.npy', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('./results_0401', 'tsne.pkl'), 'wb') as f:\n",
    "    pickle.dump(tsne, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('./results_0401', 'tsne.pkl'), 'rb') as f:\n",
    "    tsne = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue = df['origin_label'][df['origin_label'].isin([1,2])]\n",
    "sns.relplot(x=x, y=y, hue=hue, palette=sns.color_palette(color, len(np.unique(hue))))\n",
    "plt.show()\n",
    "\n",
    "hue = sub_df['Subtype_label']\n",
    "sns.relplot(x=x, y=y, hue=hue, palette=sns.color_palette(color, len(np.unique(hue))))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TSNE xy to cluster\n",
    "tmp = np.vstack([x,y]).T\n",
    "method = AgglomerativeClustering(n_clusters=4)\n",
    "clustering = method.fit(tmp)\n",
    "tmp_label = clustering.labels_.tolist()\n",
    "sns.relplot(x=x, y=y, hue=tmp_label, palette=sns.color_palette(color, len(np.unique(tmp_label))))\n",
    "plt.show()\n",
    "\n",
    "#sub_df['Subtype_label'] = clustering.labels_.tolist()\n",
    "#sub_df.to_csv(os.path.join(out_dir, 'subtype.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### center pie plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(row):\n",
    "    return row['Center_name'][:4]\n",
    "sub_df['Dataset'] = sub_df.apply(f, axis=1)\n",
    "array = sub_df.groupby([\"Dataset\",\"Subtype_label\"]).size()\n",
    "print(array)\n",
    "print(array/np.sum(array)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "radius = 1.5\n",
    "size = 0.7\n",
    "\n",
    "def f(row):\n",
    "    return row['Center_name'][:4]\n",
    "sub_df['Dataset'] = sub_df.apply(f, axis=1)\n",
    "\n",
    "array = sub_df.groupby([\"Dataset\",\"Subtype_label\"]).size()\n",
    "\n",
    "labels = []\n",
    "cs = []\n",
    "for i in array.index:\n",
    "    a, b = i\n",
    "    labels.append(f'{a}_{b}')\n",
    "    cs.append(color[b])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(array, \n",
    "        labels=labels,\n",
    "        pctdistance=0.82,\n",
    "        radius=radius, colors=cs,\n",
    "        wedgeprops=dict(width=size, edgecolor='w'))\n",
    "ax.pie(sub_df.groupby([\"Dataset\",\"Subtype_label\",'origin_label']).size(),\n",
    "        radius=radius-size, colors=['#dddddd', '#aaaaaa'],\n",
    "        wedgeprops=dict(width=0.2, edgecolor='w'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_color = ['#9dd5fe', '#fec69d']\n",
    "edgecolor = ['#3cacfd', '#fd8d3c']\n",
    "\n",
    "x = np.unique(sub_df['Subtype_label'])\n",
    "width = 0.4\n",
    "linewidth = 2\n",
    "height = sub_df.groupby([\"Subtype_label\", 'origin_label', \"gender\"]).size()\n",
    "print(height)\n",
    "\n",
    "mci_female_count = height[::4]\n",
    "mci_male_count = height[1::4]\n",
    "ad_female_count = height[2::4]\n",
    "ad_male_count = height[3::4]\n",
    "\n",
    "plt.bar(x, mci_male_count, width=-width, align='edge',\n",
    "            label='MCI_Male', color=gender_color[0], edgecolor=edgecolor[0],\n",
    "            linewidth=linewidth)\n",
    "plt.bar(x, mci_female_count, width=-width,\n",
    "            bottom=mci_male_count, align='edge',\n",
    "            label='MCI_Female', color=gender_color[1], edgecolor=edgecolor[1],\n",
    "            linewidth=linewidth)\n",
    "plt.bar(x, ad_male_count, width=width, align='edge',\n",
    "            label='AD_Male', color=gender_color[0], edgecolor=edgecolor[0],\n",
    "            linewidth=linewidth)\n",
    "plt.bar(x, ad_female_count, width=width,\n",
    "            bottom=ad_male_count,align='edge',\n",
    "            label='AD_Female', color=gender_color[1], edgecolor=edgecolor[1],\n",
    "            linewidth=linewidth)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()\n",
    "#plt.savefig(os.path.join(out_dir, f'gender.jpg'))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All dataset Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def plot_subtype_stat(df, name, out_dir, palette, boxen_width=0.6):\n",
    "    ls = np.unique(df['Subtype_label'])\n",
    "    clinical_features = [[] for _ in ls]\n",
    "    x = []\n",
    "    y = []\n",
    "    for label, row in df.iterrows():\n",
    "        x.append(row['Subtype_label'])\n",
    "        y.append(row[name])\n",
    "        clinical_features[row['Subtype_label']-1].append(row[name])\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    ax = fig.add_subplot()\n",
    "    ax = sns.boxenplot(x=x, y=y, palette=palette, width=boxen_width, saturation=1)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    plt.savefig(os.path.join(out_dir, f'{name}.jpg'))\n",
    "    plt.close()\n",
    "    with open(os.path.join(out_dir, \"t.txt\"), \"a\") as f:\n",
    "        print(f'----------{name}--------------', file=f)\n",
    "        label_pairs = []\n",
    "        for l in ls:\n",
    "            for ll in ls:\n",
    "                if ll > l:\n",
    "                    label_pairs.append([l-1, ll-1])\n",
    "        for label_pair in label_pairs:\n",
    "            array_1 = np.array(clinical_features[label_pair[0]])\n",
    "            array_1 = array_1[~np.isnan(array_1)]\n",
    "            array_2 = np.array(clinical_features[label_pair[1]])\n",
    "            array_2 = array_2[~np.isnan(array_2)]\n",
    "            t, p = ttest_ind(array_1, array_2)\n",
    "            print(name, label_pair[0]+1, label_pair[1]+1, t, p, array_1.shape[0], array_2.shape[0], file=f)\n",
    "        print(f'----------------------------', file=f)\n",
    "\n",
    "out_dir = './results_0401/subtype/g_agt4'\n",
    "plot_subtype_stat(sub_df, 'MMSE', out_dir, sns.color_palette(color, 4))\n",
    "plot_subtype_stat(sub_df, 'Mean_PS', out_dir, sns.color_palette(color, 4))\n",
    "plot_subtype_stat(sub_df, 'Age', out_dir, sns.color_palette(color, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADNI Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "def get_clinical_value(info_df, df, clinical_name):\n",
    "    values = []\n",
    "    for label, row in df.iterrows():\n",
    "        try:\n",
    "            series = info_df.loc[row['Person_name']]\n",
    "            value = series[clinical_name]\n",
    "            if isinstance(value, str):\n",
    "                continue\n",
    "            if not np.isnan(value):\n",
    "                values.append(float(value))\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return values\n",
    "\n",
    "info_df = pd.read_csv('./data/center_info/ADNI/ADNIMERGE_BL.csv', index_col=0)\n",
    "column_names = ['FAQ', 'FDG', 'ABETA', 'TAU', 'PTAU', 'ADAS11', 'ADAS13', 'ADASQ4',\n",
    "                'RAVLT_immediate', 'RAVLT_learning', 'RAVLT_forgetting', 'RAVLT_perc_forgetting']\n",
    "\n",
    "sub_df1 = sub_df.query('Subtype_label==1')\n",
    "sub_df2 = sub_df.query('Subtype_label==2')\n",
    "sub_df3 = sub_df.query('Subtype_label==3')\n",
    "\n",
    "with open(os.path.join(out_dir, \"t.txt\"), \"a\") as f:\n",
    "    for column_name in column_names:\n",
    "        values1 = get_clinical_value(info_df, sub_df1, column_name)\n",
    "        values2 = get_clinical_value(info_df, sub_df2, column_name)\n",
    "        values3 = get_clinical_value(info_df, sub_df3, column_name)\n",
    "        values = values1 + values2 + values3\n",
    "        predict_labels = [1 for _ in values1] + [2 for _ in values2] + [3 for _ in values3]\n",
    "        fig = plt.figure(figsize=(4,4))\n",
    "        ax = fig.add_subplot()\n",
    "        ax = sns.boxenplot(y=values, x=predict_labels, palette=sns.color_palette(color, 3))\n",
    "        ax.set_title(column_name)\n",
    "        plt.savefig(f'./results_0401/tmp/{column_name}.png')\n",
    "        plt.close()\n",
    "        #plt.show()\n",
    "\n",
    "        clinical_features = [values1, values2, values3]\n",
    "\n",
    "        print(f'-------{column_name}----------', file=f)\n",
    "        ls = [1, 2, 3]\n",
    "        label_pairs = []\n",
    "        for l in ls:\n",
    "            for ll in ls:\n",
    "                if ll > l:\n",
    "                    label_pairs.append([l-1, ll-1])\n",
    "        for label_pair in label_pairs:\n",
    "            array_1 = np.array(clinical_features[label_pair[0]])\n",
    "            array_1 = array_1[~np.isnan(array_1)]\n",
    "            array_2 = np.array(clinical_features[label_pair[1]])\n",
    "            array_2 = array_2[~np.isnan(array_2)]\n",
    "            t, p = ttest_ind(array_1, array_2)\n",
    "            \n",
    "            print(column_name, label_pair[0]+1, label_pair[1]+1, t, p, array_1.shape[0], array_2.shape[0], file=f)\n",
    "        print(f'----------------------------', file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(out_dir, \"t.txt\"), \"a\") as f:\n",
    "    for column_name in column_names:\n",
    "        info_df = pd.read_csv('./data/center_info/ADNI/ADNIMERGE_BL.csv', index_col=0)\n",
    "        ls = np.unique(df['Subtype_label'])\n",
    "        clinical_features = [[] for _ in ls]\n",
    "        x = []\n",
    "        y = []\n",
    "        for label, row in df.iterrows():\n",
    "            try:\n",
    "                series = info_df.loc[row['Person_name']]\n",
    "                value = series[column_name]\n",
    "                if isinstance(value, str):\n",
    "                    continue\n",
    "                if not np.isnan(value):\n",
    "                    x.append(row['Subtype_label'])\n",
    "                    y.append(float(value))\n",
    "                    clinical_features[row['Subtype_label']].append(float(value))\n",
    "            except KeyError:\n",
    "                pass\n",
    "        print([len(clinical_features[i]) for i in range(len(ls))])\n",
    "        fig = plt.figure(figsize=(3,4))\n",
    "        ax = fig.add_axes()\n",
    "        ax = sns.boxenplot(x=x, y=y, palette=palette, width=boxen_width, saturation=1)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        plt.savefig(os.path.join(out_dir, f'{column_name}.jpg'))\n",
    "        plt.close()\n",
    "    \n",
    "        print(f'-------{column_name}----------', file=f)\n",
    "        label_pairs = []\n",
    "        for l in ls:\n",
    "            for ll in ls:\n",
    "                if ll > l:\n",
    "                    label_pairs.append([l, ll])\n",
    "        for label_pair in label_pairs:\n",
    "            array_1 = np.array(clinical_features[label_pair[0]])\n",
    "            array_1 = array_1[~np.isnan(array_1)]\n",
    "            array_2 = np.array(clinical_features[label_pair[1]])\n",
    "            array_2 = array_2[~np.isnan(array_2)]\n",
    "            t, p = ttest_ind(array_1, array_2)\n",
    "            \n",
    "            print(label_pair, t, p, array_1.shape, array_2.shape, file=f)\n",
    "        print(f'----------------------------', file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal scores vs ADNI PET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abeta_pet\n",
    "import pet_fdg\n",
    "abeta_t, _ = abeta_pet.ttest_by_label(2, 0)\n",
    "fdg_t, _ =  pet_fdg.ttest_by_label(2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, pearsonr\n",
    "from draw_results import plot_correlation_joint\n",
    "\n",
    "load_dir = f'./results_0401/subtype/g_agt4'\n",
    "all_features = all_ps\n",
    "all_nc_features = all_features[df['origin_label'].values==0]\n",
    "all_features = all_features[df['origin_label'].isin([1,2])]\n",
    "\n",
    "sub_df = pd.read_csv(os.path.join(load_dir, 'subtype.csv'))\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 0, 'Subtype_label'] = 11\n",
    "sub_df.loc[sub_df.Subtype_label == 1, 'Subtype_label'] = 12\n",
    "sub_df.loc[sub_df.Subtype_label == 2, 'Subtype_label'] = 13\n",
    "sub_df.loc[sub_df.Subtype_label == 3, 'Subtype_label'] = 14\n",
    "\n",
    "sub_df.loc[sub_df.Subtype_label == 11, 'Subtype_label'] = 4\n",
    "sub_df.loc[sub_df.Subtype_label == 12, 'Subtype_label'] = 3\n",
    "sub_df.loc[sub_df.Subtype_label == 13, 'Subtype_label'] = 1\n",
    "sub_df.loc[sub_df.Subtype_label == 14, 'Subtype_label'] = 2\n",
    "\n",
    "all_labels = sub_df['Subtype_label'].values\n",
    "print(all_features.shape)\n",
    "print(all_labels.shape)\n",
    "\n",
    "ls = np.unique(all_labels)\n",
    "for l in ls:\n",
    "    all_features_label = None\n",
    "    for feature, label in zip(all_features, all_labels):\n",
    "        if label == l:\n",
    "            if all_features_label is None:\n",
    "                all_features_label = feature\n",
    "            else:\n",
    "                all_features_label = np.vstack((all_features_label, feature))\n",
    "    ts, ps = ttest_ind(all_features_label, all_nc_features, axis=0)\n",
    "    plot_correlation_joint(ts, list(abeta_t.values()),\n",
    "                          x_label=f'Subtype{l}-NC ROI t-values', y_label='AD-NC Abeta ROI t-values',\n",
    "                          save=True,\n",
    "                          out_path=f'./results_0401/tmp/Subtype{l}_abeta.png')\n",
    "    plot_correlation_joint(ts, list(fdg_t.values()),\n",
    "                            x_label=f'Subtype{l}-NC ROI t-values', y_label='AD-NC FDG ROI t-values',\n",
    "                            save=True,\n",
    "                          out_path=f'./results_0401/tmp/Subtype{l}_FDG.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abeta_pet import create_subject_df\n",
    "subject_df = create_subject_df()\n",
    "subject_df = subject_df.set_index('Name')\n",
    "subject_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "rs = []\n",
    "ps = []\n",
    "i = 0\n",
    "for k, row in df.iterrows():\n",
    "    pss = all_ps[i]\n",
    "    try:\n",
    "        pet_row = subject_df.loc[row['Person_name']]\n",
    "        #if pet_row['Label'] == 1:\n",
    "        pet_values = pet_row[4:].values\n",
    "        r, p = pearsonr(pss, pet_values)\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    i += 1\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.displot(rs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(246):\n",
    "    a = all_ps[:, i]\n",
    "    b = subject_df[f'{i+1}'].values\n",
    "    r, p = pearsonr(a, b)\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FDG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pet_fdg import create_subject_df\n",
    "subject_df = create_subject_df()\n",
    "subject_df = subject_df.set_index('Name')\n",
    "subject_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "rs = []\n",
    "ps = []\n",
    "i = 0\n",
    "for k, row in df.iterrows():\n",
    "    pss = all_ps[i]\n",
    "    try:\n",
    "        pet_row = subject_df.loc[row['Person_name']]\n",
    "        fdg_df = pd.read_csv(pet_row['sum_path'])\n",
    "        pet_values = fdg_df['GMV'].values\n",
    "        r, p = pearsonr(pss, pet_values)\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    i += 1\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.displot(rs)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f4d9276dd5f4159fcfc6e7340f2d8c674abaee8f07fe7a5c7e9a65c0e06a4fc3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('meta')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
